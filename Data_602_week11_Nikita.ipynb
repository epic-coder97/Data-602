{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_602_week11_Nikita.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/epic-coder97/Data-602/blob/main/Data_602_week11_Nikita.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Nikita Dharmadhikari*"
      ],
      "metadata": {
        "id": "1eCNgZXwQZE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 1.\n",
        "1. Install preprocessing with Keras\n",
        "2. Load all the necessary libraries\n",
        "3. Load tensorflow.keras.models\n",
        "4. Load the dataset using from keras.datasets import imdb\n",
        "5. Limit the number of words to 10,000 in the training and testing datasets\n",
        "6. Print the number of unique categories for the target variable\n",
        "7. Print the average review length\n",
        "8. Print the standard deviation\n",
        "9. Vectorize sequences and dimension with a size of 10,000\n",
        "10. Make sure the test and train variables represent 10,000 observations\n",
        "11. Import Sequential, Flatten, Dropout, and Dense from tensorflow.keras.models\n",
        "12. Use the following parameters with an ‘adam’ optimizer and ‘binary_crossentropy’\n",
        "loss function:\n",
        "13. Compile, train, and evaluate the model with epochs=20, batch_size=512,\n",
        "validation_data=(test_x,test_y)\n",
        "14. Provide the loss and accuracy for 20 epochs"
      ],
      "metadata": {
        "id": "Y8r9zGjbP2x1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24v96dmNjaR2"
      },
      "source": [
        "# Install preprocessing with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7h0oK2liwfe",
        "outputId": "8a6bf5f2-84a8-4f1b-c385-c6ec84a59b4a"
      },
      "source": [
        "!pip install Keras-Preprocessing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Keras-Preprocessing in /usr/local/lib/python3.7/dist-packages (1.1.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from Keras-Preprocessing) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras-Preprocessing) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXe-KDJjjWPV"
      },
      "source": [
        "# Load all the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GgNyoi9emt-"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS35piKsj_or"
      },
      "source": [
        "from keras import models,layers\n",
        "from keras.datasets import imdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gHsJtbcg1tm",
        "outputId": "93c91d7d-c61d-4392-a454-2faf51fc293d"
      },
      "source": [
        "\n",
        "(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=10000)\n",
        "data = np.concatenate((training_data, testing_data), axis=0)\n",
        "targets = np.concatenate((training_targets, testing_targets), axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3umwhXrGkmOy"
      },
      "source": [
        "### Print the number of unique categories for the target variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4z6r6mVkprv",
        "outputId": "cd23803f-bec3-428d-c609-998527f32d9a"
      },
      "source": [
        "print(\"number of unique categories for the target variable:\", np.unique(targets))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of unique categories for the target variable: [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg8Fy_9Vk22r"
      },
      "source": [
        "### Print the average review length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7egxUexk3Ob",
        "outputId": "257562b7-b7fc-4a7e-e6f6-3acb34b4cb95"
      },
      "source": [
        "length = [len(i) for i in data]\n",
        "print(\"Average Review length:\", np.mean(length))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Review length: 234.75892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiWFJ0RhlZNq"
      },
      "source": [
        "### Print the standard deviation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_ji3-f3lc0C",
        "outputId": "daa5f092-5a7b-4cd3-df36-eea2fe2870b2"
      },
      "source": [
        "print(\"Standard Deviation:\", round(np.std(length)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standard Deviation: 173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDnPmm9MlhS_"
      },
      "source": [
        "### Vectorize sequences and dimension with a size of 10,000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg5k2V13lhp8"
      },
      "source": [
        "def vectorize(sequences, dimension = 10000):\n",
        "  results = np.zeros((len(sequences), dimension))\n",
        "  for i, sequence in enumerate(sequences):\n",
        "    results[i, sequence] = 1\n",
        "  return results\n",
        " \n",
        "data = vectorize(data)\n",
        "targets = np.array(targets).astype(\"float32\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnGmvRMkpCPt"
      },
      "source": [
        "### Make sure the test and train variables represent 10,000 observations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFgNRTEEpGFL"
      },
      "source": [
        "test_x = data[:10000]\n",
        "test_y = targets[:10000]\n",
        "train_x = data[:10000]\n",
        "train_y = targets[:10000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHizNs3fpRS_"
      },
      "source": [
        "### Import Sequential, Flatten, Dropout, and Dense from tensorflow.keras.models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eX24ipJpQVG",
        "outputId": "957c8be9-016f-48ad-ded2-6af8a52d0b7b"
      },
      "source": [
        "model = models.Sequential()\n",
        "# Input - Layer\n",
        "model.add(layers.Dense(50, activation = \"relu\", input_shape=(10000, )))\n",
        "# Hidden - Layers\n",
        "model.add(layers.Dropout(0.5, noise_shape=None, seed=None))\n",
        "model.add(layers.Dense(1024, activation = \"relu\"))\n",
        "model.add(layers.Dropout(0.5, noise_shape=None, seed=None))\n",
        "model.add(layers.Dense(2, activation = \"relu\"))\n",
        "# Output- Layer\n",
        "model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 50)                500050    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 50)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              52224     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 2050      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 554,327\n",
            "Trainable params: 554,327\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "993T-FFWu17p"
      },
      "source": [
        "### Use the following parameters with an ‘adam’ optimizer and ‘binary_crossentropy’ loss function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PybalmkWps8d"
      },
      "source": [
        "model.compile(\n",
        " optimizer = \"adam\",\n",
        " loss = \"binary_crossentropy\",\n",
        " metrics = ['accuracy', 'binary_crossentropy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dvfv3emyxteO"
      },
      "source": [
        "### Compile, train, and evaluate the model with epochs=20, batch_size=512, validation_data=(test_x,test_y) and Providing the loss and accuracy for 20 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7CKfSjlxpca",
        "outputId": "4cb882bc-8292-4347-9751-2d4933f751fc"
      },
      "source": [
        "results = model.fit(\n",
        " train_x, train_y,\n",
        " epochs= 20,\n",
        " batch_size = 512,\n",
        " validation_data = (test_x, test_y)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "20/20 [==============================] - 7s 258ms/step - loss: 0.6714 - accuracy: 0.5774 - binary_crossentropy: 0.6714 - val_loss: 0.5693 - val_accuracy: 0.8462 - val_binary_crossentropy: 0.5693\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 3s 169ms/step - loss: 0.4555 - accuracy: 0.8228 - binary_crossentropy: 0.4555 - val_loss: 0.2433 - val_accuracy: 0.9174 - val_binary_crossentropy: 0.2433\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 3s 139ms/step - loss: 0.2658 - accuracy: 0.8985 - binary_crossentropy: 0.2658 - val_loss: 0.1533 - val_accuracy: 0.9544 - val_binary_crossentropy: 0.1533\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 2s 87ms/step - loss: 0.1724 - accuracy: 0.9401 - binary_crossentropy: 0.1724 - val_loss: 0.1095 - val_accuracy: 0.9619 - val_binary_crossentropy: 0.1095\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.1176 - accuracy: 0.9588 - binary_crossentropy: 0.1176 - val_loss: 0.0580 - val_accuracy: 0.9851 - val_binary_crossentropy: 0.0580\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.0800 - accuracy: 0.9743 - binary_crossentropy: 0.0800 - val_loss: 0.0346 - val_accuracy: 0.9926 - val_binary_crossentropy: 0.0346\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.0524 - accuracy: 0.9854 - binary_crossentropy: 0.0524 - val_loss: 0.0206 - val_accuracy: 0.9955 - val_binary_crossentropy: 0.0206\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.0408 - accuracy: 0.9876 - binary_crossentropy: 0.0408 - val_loss: 0.0145 - val_accuracy: 0.9973 - val_binary_crossentropy: 0.0145\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 2s 85ms/step - loss: 0.0317 - accuracy: 0.9911 - binary_crossentropy: 0.0317 - val_loss: 0.0099 - val_accuracy: 0.9975 - val_binary_crossentropy: 0.0099\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 2s 85ms/step - loss: 0.0253 - accuracy: 0.9919 - binary_crossentropy: 0.0253 - val_loss: 0.0072 - val_accuracy: 0.9984 - val_binary_crossentropy: 0.0072\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 2s 85ms/step - loss: 0.0222 - accuracy: 0.9942 - binary_crossentropy: 0.0222 - val_loss: 0.0046 - val_accuracy: 0.9989 - val_binary_crossentropy: 0.0046\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 2s 85ms/step - loss: 0.0147 - accuracy: 0.9955 - binary_crossentropy: 0.0147 - val_loss: 0.0038 - val_accuracy: 0.9993 - val_binary_crossentropy: 0.0038\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.0143 - accuracy: 0.9950 - binary_crossentropy: 0.0143 - val_loss: 0.0026 - val_accuracy: 0.9994 - val_binary_crossentropy: 0.0026\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.0115 - accuracy: 0.9968 - binary_crossentropy: 0.0115 - val_loss: 0.0020 - val_accuracy: 0.9995 - val_binary_crossentropy: 0.0020\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 2s 85ms/step - loss: 0.0147 - accuracy: 0.9955 - binary_crossentropy: 0.0147 - val_loss: 0.0027 - val_accuracy: 0.9995 - val_binary_crossentropy: 0.0027\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 2s 87ms/step - loss: 0.0119 - accuracy: 0.9963 - binary_crossentropy: 0.0119 - val_loss: 0.0015 - val_accuracy: 0.9995 - val_binary_crossentropy: 0.0015\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 2s 85ms/step - loss: 0.0101 - accuracy: 0.9963 - binary_crossentropy: 0.0101 - val_loss: 0.0014 - val_accuracy: 0.9995 - val_binary_crossentropy: 0.0014\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.0097 - accuracy: 0.9968 - binary_crossentropy: 0.0097 - val_loss: 0.0011 - val_accuracy: 0.9995 - val_binary_crossentropy: 0.0011\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 2s 86ms/step - loss: 0.0068 - accuracy: 0.9977 - binary_crossentropy: 0.0068 - val_loss: 8.8994e-04 - val_accuracy: 0.9998 - val_binary_crossentropy: 8.8994e-04\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 2s 85ms/step - loss: 0.0065 - accuracy: 0.9978 - binary_crossentropy: 0.0065 - val_loss: 7.8639e-04 - val_accuracy: 1.0000 - val_binary_crossentropy: 7.8639e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faMgHP8S5wup"
      },
      "source": [
        "# Exercise 2 "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. from keras.processing.text import Tokenizer\n",
        "2. Use keras to build a ‘Sequential’ model\n",
        "3. Use the following model:\n",
        "epochs = 20\n",
        "maxlen = 100\n",
        "embedding_dim = 50\n",
        "num_filters = 64\n",
        "kernel_size = 5\n",
        "batch_size = 32\n",
        "4. Use the ‘yelp_labelled.txt’\n",
        "5. Use ‘sentence’ as feature and ‘label’ as target\n",
        "6. Tokenizer with 5,000 words\n",
        "7. Pad the X_train and X_test values\n",
        "8. Use a ‘Sequential()’ model with\n",
        "9. Determine the loss, accuracy of the training and testing model"
      ],
      "metadata": {
        "id": "Sp66z3W6QJO8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDZEGIlr9-HZ"
      },
      "source": [
        "### from keras.processing.text importing Tokenizer and Using keras to build a ‘Sequential’ model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Jl36NHDx1v1"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdOOK1W7_GDu"
      },
      "source": [
        "### Using the ‘yelp_labelled.txt’"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9LHLC3175Jc",
        "outputId": "888bf4cb-b591-4694-e787-93d1b1078b00"
      },
      "source": [
        "! git clone 'https://github.com/saideep-reddy-m/saideep-reddy-m'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'saideep-reddy-m'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 18 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (18/18), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pXyrNlgv6Bqb",
        "outputId": "29062751-c437-47b1-9994-37f7595511e7"
      },
      "source": [
        "# Importing the data into a pandas Dataframe.\n",
        "df = pd.read_csv('/content/saideep-reddy-m/yelp_labelled.txt',names=['text', 'label'], sep='\\t')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0                           Wow... Loved this place.      1\n",
              "1                                 Crust is not good.      0\n",
              "2          Not tasty and the texture was just nasty.      0\n",
              "3  Stopped by during the late May bank holiday of...      1\n",
              "4  The selection on the menu was great and so wer...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba5e564f-38d8-445e-86a8-90033febba6e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba5e564f-38d8-445e-86a8-90033febba6e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba5e564f-38d8-445e-86a8-90033febba6e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba5e564f-38d8-445e-86a8-90033febba6e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5llOyTW-Bbad"
      },
      "source": [
        "### Using ‘sentence’ as feature and ‘label’ as target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEXYdQpM6N8T"
      },
      "source": [
        "sentence=df['text'].values\n",
        "labels=df['label'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uHL7JyR_vK6"
      },
      "source": [
        "### spliting data into test and train datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoDiBluX6V4P"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(sentence, labels, test_size=0.30, random_state=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBSvcJpS_jyT"
      },
      "source": [
        "### Tokenizer with 5,000 words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKjBRXWT6YKq"
      },
      "source": [
        "token = Tokenizer(num_words=5000)\n",
        "token.fit_on_texts(X_train)\n",
        "X_train = token.texts_to_sequences(X_train)\n",
        "X_test = token.texts_to_sequences(X_test)\n",
        "vocab_size = len(token.word_index) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7vENLl9546q"
      },
      "source": [
        "epochs = 20\n",
        "maxlen = 100\n",
        "embedding_dim = 50\n",
        "num_filters = 64\n",
        "kernel_size = 5\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8QuWMZe_okI"
      },
      "source": [
        "### Pading the X_train and X_test values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vI6q-xR6lpx"
      },
      "source": [
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDXi6jSN_6SX"
      },
      "source": [
        "### Use a ‘Sequential()’ model with above values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMo5zMGl6nZl"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
        "model.add(layers.Conv1D(num_filters, kernel_size, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(10, activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffOz5mmG6pEn",
        "outputId": "9d15f6e8-eef1-46a7-cb23-fd62258baccb"
      },
      "source": [
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "loss='binary_crossentropy',\n",
        "metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 50)           84900     \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 96, 64)            16064     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 64)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 101,625\n",
            "Trainable params: 101,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-IcrybMALez"
      },
      "source": [
        "### Determining the loss, accuracy of the training and testing model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scg79K2r6rfS",
        "outputId": "eb64e957-3c9c-4160-dcad-f6a4b10c31ad"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=epochs, verbose=False, validation_data=(X_test, y_test), batch_size=batch_size)\n",
        "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Train set Accuracy is {}  and  loss is {} \".format(accuracy,loss))\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Test set Accuracy is  {} and  loss is {}\".format(accuracy,loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set Accuracy is 1.0  and  loss is 0.001396121340803802 \n",
            "Test set Accuracy is  0.7866666913032532 and  loss is 0.6358831524848938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iY95yvN6uBe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}